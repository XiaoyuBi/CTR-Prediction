{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_detail = pd.read_csv('ctr_data/table_poi_detail.csv')\n",
    "request_detail = pd.read_csv('ctr_data/table_request_detail.csv')\n",
    "request_detail.drop_duplicates(subset = 'request_id', keep = 'first', inplace = True)\n",
    "user_detail = pd.read_csv('ctr_data/table_uuid_detail.csv')\n",
    "user_detail.drop_duplicates(subset = 'uuid', keep = 'first', inplace = True)\n",
    "deal_detail = pd.read_csv('ctr_data/table_deal_detail.csv')\n",
    "train = pd.read_csv('ctr_data/table_impr_click_action_train.csv')\n",
    "test = pd.read_csv('ctr_data/table_impr_click_action_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['train_test'] = 1\n",
    "test['train_test'] = 0\n",
    "train_test = pd.concat([train, test], axis = 0)\n",
    "#train_test.drop(['ID', 'pos', 'time'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cannot merge user_detail\n",
    "request_user = request_detail.merge(user_detail, on = 'uuid', how = 'left')\n",
    "train_test = train_test.merge(request_user, on = 'request_id', how = 'left').\\\n",
    "              merge(poi_detail, on = 'poi_id', suffixes=['_req', '_poi'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test = train_test.merge(deal_detail, on = 'poi_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test['device_type'].fillna('NA', inplace = True)\n",
    "train_test['avg_price'].fillna(train_test['avg_price'].mean(), inplace = True)\n",
    "train_test['age'].fillna(train_test['age'].mean(), inplace = True)\n",
    "train_test['request_time'].fillna('00', inplace = True)\n",
    "train_test.fillna(-1.0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'action', 'poi_id', 'pos', 'request_id', 'time', 'train_test',\n",
       "       'uuid', 'cate_id', 'request_time', 'latitude_req', 'longitude_req',\n",
       "       'device_type', 'gender', 'age', 'job', 'cate_level1', 'cate_level2',\n",
       "       'cate_level3', 'area_id', 'avg_price', 'poi_star', 'longitude_poi',\n",
       "       'latitude_poi', 'deal_id', 'price', 'discount_price'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess\n",
    "from sklearn import preprocessing\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "standard = preprocessing.StandardScaler()\n",
    "train_test.loc[:, 'device_type'] = pd.Series(encoder.fit_transform(train_test.loc[:, 'device_type']))\n",
    "train_test['age'] = standard.fit_transform((train_test['age']).values.reshape(-1, 1))\n",
    "train_test['avg_price'] = standard.fit_transform((train_test['avg_price']).values.reshape(-1, 1))\n",
    "train_test['poi_star'] = standard.fit_transform((train_test['poi_star']).values.reshape(-1, 1))\n",
    "#train_temp.loc[:, 'area_id'] = pd.Series(encoder.fit_transform(train_temp.loc[:, 'area_id']))\n",
    "#train_temp.loc[:, 'cate_id'] = pd.Series(encoder.fit_transform(train_temp.loc[:, 'cate_id']))\n",
    "#train_temp.loc[:, 'cate_level1'] = pd.Series(encoder.fit_transform(train_temp.loc[:, 'cate_level1']))\n",
    "#train_temp.loc[:, 'cate_level2'] = pd.Series(encoder.fit_transform(train_temp.loc[:, 'cate_level2']))\n",
    "#train_temp.loc[:, 'cate_level3'] = pd.Series(encoder.fit_transform(train_temp.loc[:, 'cate_level3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test['hour'] = train_test['request_time'].apply(lambda x: int(x[0:2]))\n",
    "train_test['week'] = train_test['time'].apply(lambda x: int(x[-2:])%7)\n",
    "#train_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discretization By K-means\n",
    "'''from sklearn.cluster import KMeans\n",
    " \n",
    "kmodel = KMeans(n_clusters = 20, n_jobs = 4) \n",
    "kmodel.fit(np.array(train_test['avg_price']).reshape((len(train_test['avg_price']), 1)))\n",
    "kmodel_pred = kmodel.predict(np.array(train_test['avg_price']).reshape((len(train_test['avg_price']), 1)))\n",
    "train_test.loc[:, 'avg_price_type'] = kmodel_pred'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "needed_columns = ['poi_id', 'uuid', 'cate_id', 'hour', 'longitude_req', 'latitude_req',\n",
    "               'device_type', 'gender', 'age', 'job', 'longitude_poi', 'latitude_poi',\n",
    "                'cate_level2', 'cate_level3', 'area_id', 'week', 'deal_id', 'price', 'discount_price',\n",
    "               'avg_price', 'poi_star']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import utils\n",
    "\n",
    "def undersampling(train, undersampling_rate):\n",
    "\n",
    "    # Get the indices per target value\n",
    "    idx_0 = train[train.action == 0].index\n",
    "    idx_1 = train[train.action >= 1].index\n",
    "    # Get original number of records per target value\n",
    "    nb_0 = len(train.loc[idx_0])\n",
    "    nb_1 = len(train.loc[idx_1])\n",
    "    # Calculate the undersampling rate and resulting number of records with target=0\n",
    "    undersampled_nb_0 = int(undersampling_rate*nb_0)\n",
    "    print('Rate to undersample records with action = 0: {}'.format(undersampling_rate))\n",
    "    print('Number of records with action = 0 after undersampling: {}'.format(undersampled_nb_0))\n",
    "    # Randomly select records with target=0 to get at the desired a priori\n",
    "    undersampled_idx = utils.shuffle(idx_0, n_samples = undersampled_nb_0)\n",
    "    # Construct list with remaining indices\n",
    "    idx_list = list(undersampled_idx) + list(idx_1)\n",
    "    # Return undersample data frame\n",
    "    train = train.loc[idx_list].reset_index(drop = True)\n",
    "\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_undersampling = undersampling(train_test, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_test_undersampling[needed_columns]\n",
    "y = train_test_undersampling['action'] >= 1\n",
    "y = y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(x, y, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "dtrain = lgb.Dataset(X_train, y_train)\n",
    "dval = lgb.Dataset(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'metric':'auc',\n",
    "    'learning_rate':0.01,\n",
    "    'num_leaves':127,\n",
    "    'objective':'binary',\n",
    "    'n_jobs':6,\n",
    "    'early_stopping_round': 100,\n",
    "    'feature_fraction':0.8,\n",
    "    'feature_fraction_seed':2019\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = lgb.train(params, dtrain, num_boost_round = 1000, valid_sets = dval, verbose_eval = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM Parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.plot_importance(clf, max_num_features = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.save_model('model/model3.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test w = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = train_test[train_test['action'] == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_xgb_test = clf.predict(a[needed_columns])\n",
    "preds_xgb_test_re = preds_xgb_test/(preds_xgb_test+(1-preds_xgb_test)/0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['preds_xgb_test_re'] = preds_xgb_test_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.groupby(by = ['poi_id', 'request_id'], sort = False).agg('mean').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testoutput = pd.DataFrame()\n",
    "testoutput['action'] = a['preds_xgb_test_re']\n",
    "testoutput.index.name = 'ID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testoutput.to_csv('output/testoutputV2.11.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testoutput.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
